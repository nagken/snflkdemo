<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Snowflake Cortex GenAI Pipeline - Flow Diagrams</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f5f5f5;
        }
        .diagram-container {
            background: white;
            margin: 20px 0;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            text-align: center;
        }
        h2 {
            color: #3498db;
            border-bottom: 2px solid #3498db;
            padding-bottom: 5px;
        }
        .mermaid {
            text-align: center;
        }
    </style>
</head>
<body>
    <h1>Snowflake Cortex GenAI Pipeline - Flow Diagrams</h1>

    <div class="diagram-container">
        <h2>1. High-Level Architecture Flow</h2>
        <div class="mermaid">
graph TB
    %% Input Sources
    PDF[ðŸ“„ PDF Files] --> INGEST[ðŸ“¥ Document Ingestion]
    DOCX[ðŸ“„ DOCX Files] --> INGEST
    TXT[ðŸ“„ Text Files] --> INGEST
    MD[ðŸ“„ Markdown Files] --> INGEST
    
    %% Ingestion Pipeline
    INGEST --> EXTRACT[ðŸ”§ Text Extraction]
    EXTRACT --> CHUNK[âœ‚ï¸ Text Chunking]
    CHUNK --> VALIDATE[âœ… Content Validation]
    VALIDATE --> STORE_RAW[ðŸ—„ï¸ Raw Documents Table]
    
    %% Embedding Pipeline
    STORE_RAW --> EMBED_GEN[ðŸ§  Embedding Generation]
    EMBED_GEN --> CORTEX_EMBED[â„ï¸ CORTEX.EMBED_TEXT_768]
    CORTEX_EMBED --> STORE_VEC[ðŸ“Š Vector Embeddings Table]
    
    %% Query Pipeline
    USER_Q[â“ User Query] --> QUERY_EMBED[ðŸ” Query Embedding]
    QUERY_EMBED --> CORTEX_EMBED
    CORTEX_EMBED --> SEARCH[ðŸŽ¯ Vector Similarity Search]
    
    SEARCH --> STORE_VEC
    STORE_VEC --> SIMILAR[ðŸ“‹ Top-K Similar Chunks]
    SIMILAR --> CONTEXT[ðŸ“ Build Context]
    
    %% LLM Pipeline
    CONTEXT --> PROMPT[ðŸ’¬ Enhanced Prompt]
    USER_Q --> PROMPT
    PROMPT --> LLM[ðŸ¤– CORTEX.COMPLETE]
    LLM --> RESPONSE[ðŸ’¡ Generated Response]
    
    %% Monitoring & Storage
    EMBED_GEN --> TELEMETRY[ðŸ“ˆ Telemetry Table]
    SEARCH --> TELEMETRY
    LLM --> TELEMETRY
    RESPONSE --> QUERY_HIST[ðŸ“š Query History Table]
    TELEMETRY --> DASHBOARD[ðŸ“Š Streamlit Dashboard]
    
    %% Styling
    classDef input fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef process fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef storage fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef cortex fill:#fff3e0,stroke:#e65100,stroke-width:3px
    classDef output fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    
    class PDF,DOCX,TXT,MD,USER_Q input
    class INGEST,EXTRACT,CHUNK,VALIDATE,EMBED_GEN,QUERY_EMBED,SEARCH,CONTEXT,PROMPT process
    class STORE_RAW,STORE_VEC,TELEMETRY,QUERY_HIST storage
    class CORTEX_EMBED,LLM cortex
    class SIMILAR,RESPONSE,DASHBOARD output
        </div>
    </div>

    <div class="diagram-container">
        <h2>2. Component Interaction Flow</h2>
        <div class="mermaid">
graph LR
    subgraph "ðŸ“¥ Input Layer"
        DOC[ðŸ“„ Documents]
        QUERY[â“ User Queries]
    end
    
    subgraph "âš™ï¸ Processing Layer"
        INGEST[ingest_loader.py]
        EMBED[embed_generator.py]
        CORTEX_Q[cortex_query.py]
    end
    
    subgraph "â„ï¸ Snowflake Cortex"
        CORTEX_EMB[CORTEX.EMBED_TEXT_768]
        CORTEX_LLM[CORTEX.COMPLETE]
        VECTOR_SEARCH[VECTOR_COSINE_SIMILARITY]
    end
    
    subgraph "ðŸ—„ï¸ Storage Layer"
        RAW_TBL[media_raw]
        EMB_TBL[media_embeddings]
        TEL_TBL[genai_telemetry]
        HIST_TBL[query_history]
    end
    
    subgraph "ðŸ“Š Monitoring Layer"
        TELEMETRY[telemetry_task.py]
        DASHBOARD[dashboard_plot.py]
    end
    
    subgraph "ðŸ”§ Management Layer"
        UTILS[utils.py]
        CONFIG[config/]
        CICD[pipelines/deploy.yaml]
    end
    
    %% Connections
    DOC --> INGEST
    INGEST --> RAW_TBL
    RAW_TBL --> EMBED
    EMBED --> CORTEX_EMB
    CORTEX_EMB --> EMB_TBL
    
    QUERY --> CORTEX_Q
    CORTEX_Q --> CORTEX_EMB
    CORTEX_Q --> VECTOR_SEARCH
    VECTOR_SEARCH --> EMB_TBL
    EMB_TBL --> CORTEX_Q
    CORTEX_Q --> CORTEX_LLM
    CORTEX_LLM --> CORTEX_Q
    
    CORTEX_Q --> HIST_TBL
    INGEST --> TELEMETRY
    EMBED --> TELEMETRY
    CORTEX_Q --> TELEMETRY
    TELEMETRY --> TEL_TBL
    TEL_TBL --> DASHBOARD
    
    UTILS --> INGEST
    UTILS --> EMBED
    UTILS --> CORTEX_Q
    UTILS --> TELEMETRY
    CONFIG --> UTILS
    CICD --> CONFIG
        </div>
    </div>

    <div class="diagram-container">
        <h2>3. Query Processing Sequence</h2>
        <div class="mermaid">
sequenceDiagram
    participant U as ðŸ‘¤ User
    participant API as ðŸ”Œ Query API
    participant EMB as ðŸ§  Embedding Service
    participant VS as ðŸŽ¯ Vector Search
    participant LLM as ðŸ¤– LLM Service
    participant TEL as ðŸ“ˆ Telemetry
    participant DB as â„ï¸ Snowflake DB
    
    Note over U,DB: ðŸ“š Document Ingestion Phase
    U->>API: Upload Document
    API->>DB: Store Raw Document
    API->>EMB: Generate Embeddings
    EMB->>DB: CORTEX.EMBED_TEXT_768()
    DB->>EMB: Return Vector
    EMB->>DB: Store Embeddings
    EMB->>TEL: Log Metrics
    
    Note over U,DB: â“ Query Processing Phase
    U->>API: Submit Query
    API->>EMB: Generate Query Embedding
    EMB->>DB: CORTEX.EMBED_TEXT_768()
    DB->>EMB: Return Query Vector
    
    API->>VS: Perform Similarity Search
    VS->>DB: VECTOR_COSINE_SIMILARITY()
    DB->>VS: Return Top-K Results
    VS->>TEL: Log Search Metrics
    
    API->>LLM: Enhanced Prompt + Context
    LLM->>DB: CORTEX.COMPLETE()
    DB->>LLM: Return Response
    LLM->>TEL: Log LLM Metrics
    
    API->>DB: Store Query History
    API->>U: Return Response + Metadata
    
    Note over TEL,DB: ðŸ“Š Continuous Monitoring
    TEL->>DB: Aggregate Metrics
    DB->>TEL: Performance Data
        </div>
    </div>

    <div class="diagram-container">
        <h2>4. Data Processing State Flow</h2>
        <div class="mermaid">
stateDiagram-v2
    [*] --> QueryReceived : User submits query
    QueryReceived --> ValidateInput : Check input format
    ValidateInput --> GenerateQueryEmbedding : Input valid
    ValidateInput --> ReturnError : Invalid input
    
    GenerateQueryEmbedding --> EmbeddingSuccess : Embedding created
    GenerateQueryEmbedding --> EmbeddingError : Embedding failed
    
    EmbeddingSuccess --> PerformSimilaritySearch : Search vectors
    EmbeddingError --> LogError : Record failure
    LogError --> [*]
    
    PerformSimilaritySearch --> SearchResults : Found matches
    PerformSimilaritySearch --> NoResults : No matches
    SearchResults --> BuildContext : Compile context
    NoResults --> ReturnEmpty : Return empty result
    
    BuildContext --> GeneratePrompt : Create LLM prompt
    GeneratePrompt --> LLMCompletion : Send to Cortex
    
    LLMCompletion --> CompletionSuccess : Response received
    LLMCompletion --> CompletionError : LLM error
    
    CompletionSuccess --> LogTelemetry : Record metrics
    CompletionError --> LogError : Record failure
    
    LogTelemetry --> StoreQueryHistory : Save query
    StoreQueryHistory --> ReturnResponse : Send to user
    ReturnResponse --> [*]
    ReturnError --> [*]
    ReturnEmpty --> [*]
    
    state ValidateInput {
        [*] --> CheckLength
        CheckLength --> CheckContent
        CheckContent --> [*]
    }
    
    state LogTelemetry {
        [*] --> RecordLatency
        RecordLatency --> RecordCost
        RecordCost --> RecordSuccess
        RecordSuccess --> [*]
    }
        </div>
    </div>

    <div class="diagram-container">
        <h2>5. Telemetry Data Flow</h2>
        <div class="mermaid">
flowchart TD
    subgraph "ðŸ”§ Operations"
        OP1[ðŸ“¥ Document Ingestion]
        OP2[ðŸ§  Embedding Generation]
        OP3[ðŸŽ¯ Semantic Search]
        OP4[ðŸ¤– LLM Completion]
    end
    
    subgraph "ðŸ“Š Telemetry Collection"
        TRACKER[ðŸ“ˆ TelemetryTracker]
        BUFFER[ðŸ“¦ Batch Buffer]
    end
    
    subgraph "ðŸ—„ï¸ Storage & Analysis"
        TEL_DB[genai_telemetry]
        METRICS[ðŸ“ Performance Metrics]
        COSTS[ðŸ’° Cost Analysis]
        ERRORS[âš ï¸ Error Analysis]
    end
    
    subgraph "ðŸ“± Visualization"
        DASH_PERF[ðŸ“ˆ Performance Charts]
        DASH_COST[ðŸ’° Cost Breakdown]
        DASH_ERROR[âš ï¸ Error Dashboard]
        ALERTS[ðŸš¨ Real-time Alerts]
    end
    
    OP1 --> TRACKER
    OP2 --> TRACKER
    OP3 --> TRACKER
    OP4 --> TRACKER
    
    TRACKER --> BUFFER
    BUFFER --> TEL_DB
    
    TEL_DB --> METRICS
    TEL_DB --> COSTS
    TEL_DB --> ERRORS
    
    METRICS --> DASH_PERF
    COSTS --> DASH_COST
    ERRORS --> DASH_ERROR
    ERRORS --> ALERTS
    
    DASH_PERF --> DASHBOARD_UI[ðŸ“Š Streamlit Dashboard]
    DASH_COST --> DASHBOARD_UI
    DASH_ERROR --> DASHBOARD_UI
    ALERTS --> DASHBOARD_UI
        </div>
    </div>

    <div class="diagram-container">
        <h2>6. CI/CD Pipeline Flow</h2>
        <div class="mermaid">
graph TD
    PUSH[ðŸ“¤ Git Push] --> VALIDATE[âœ… Code Validation]
    VALIDATE --> LINT[ðŸ” Linting & Testing]
    LINT --> SQL_CHECK[ðŸ“‹ SQL Validation]
    
    SQL_CHECK --> DEPLOY_INFRA[ðŸš€ Deploy Infrastructure]
    DEPLOY_INFRA --> SEED_DATA[ðŸŒ± Seed Sample Data]
    SEED_DATA --> PERF_TEST[âš¡ Performance Testing]
    
    PERF_TEST --> HEALTH_CHECK[ðŸ’š Health Checks]
    HEALTH_CHECK --> NOTIFY[ðŸ“¬ Deployment Notification]
    
    subgraph "ðŸ” Validation Steps"
        VALIDATE --> BLACK[âš« Black Formatting]
        VALIDATE --> FLAKE8[ðŸ Flake8 Linting]
        VALIDATE --> MYPY[ðŸ“ Type Checking]
        VALIDATE --> PYTEST[ðŸ§ª Unit Tests]
    end
    
    subgraph "ðŸš€ Deployment Steps"
        DEPLOY_INFRA --> CREATE_TABLES[ðŸ“Š Create Tables]
        DEPLOY_INFRA --> CREATE_FUNCTIONS[âš™ï¸ Create Functions]
        DEPLOY_INFRA --> SETUP_TELEMETRY[ðŸ“ˆ Setup Telemetry]
    end
    
    subgraph "âš¡ Testing Steps"
        PERF_TEST --> LATENCY_TEST[â±ï¸ Latency Testing]
        PERF_TEST --> SUCCESS_RATE[âœ… Success Rate Check]
        PERF_TEST --> COST_ANALYSIS[ðŸ’° Cost Analysis]
    end
        </div>
    </div>

    <script>
        mermaid.initialize({ 
            startOnLoad: true,
            theme: 'default',
            flowchart: {
                useMaxWidth: true,
                htmlLabels: true
            }
        });
    </script>
</body>
</html>